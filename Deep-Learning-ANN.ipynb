{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8450daf5-2f32-4e05-afe2-6714279f59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220408a-4191-4877-839e-8f848ac84007",
   "metadata": {},
   "source": [
    "# Importing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3b8c74-f34c-4bd1-87d9-eaccb7cf5682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Customer Since</th>\n",
       "      <th>Current Account</th>\n",
       "      <th>Num of products</th>\n",
       "      <th>UPI Enabled</th>\n",
       "      <th>Estimated Yearly Income</th>\n",
       "      <th>Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>553</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>274150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>519360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>501</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>545501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>428</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>86868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>492</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>1.912682e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>518680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>510</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Male</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>251912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>475</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>1.396908e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>487067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>624</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>259649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>557</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>8.910724e+05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>538583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>417</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>427703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7322 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Credit Score  Geography  Gender  Age  Customer Since  Current Account  \\\n",
       "0              553      Delhi  Female   45               4     0.000000e+00   \n",
       "1              447  Bengaluru    Male   31               7     0.000000e+00   \n",
       "2              501      Delhi  Female   32               2     0.000000e+00   \n",
       "3              428      Delhi    Male   51               3     0.000000e+00   \n",
       "4              492      Delhi  Female   57               6     1.912682e+06   \n",
       "...            ...        ...     ...  ...             ...              ...   \n",
       "7317           510      Delhi    Male   70               5     0.000000e+00   \n",
       "7318           475     Mumbai    Male   32               7     1.396908e+06   \n",
       "7319           624  Bengaluru    Male   38               7     0.000000e+00   \n",
       "7320           557      Delhi    Male   24               8     8.910724e+05   \n",
       "7321           417  Bengaluru    Male   42               1     0.000000e+00   \n",
       "\n",
       "      Num of products  UPI Enabled  Estimated Yearly Income  Closed  \n",
       "0                   4            1                   274150       0  \n",
       "1                   4            1                   519360       0  \n",
       "2                   4            1                   545501       0  \n",
       "3                   4            1                    86868       0  \n",
       "4                   2            1                   518680       0  \n",
       "...               ...          ...                      ...     ...  \n",
       "7317                2            0                   251912       1  \n",
       "7318                2            1                   487067       1  \n",
       "7319                4            1                   259649       0  \n",
       "7320                2            0                   538583       0  \n",
       "7321                4            0                   427703       0  \n",
       "\n",
       "[7322 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"C:\\\\Users\\\\SAMA\\\\Downloads\\\\American-Express-dataset - Sheet1.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170166c4-98fb-4ac0-9112-03a995ea44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[553 'Delhi' 'Female' ... 4 1 274150]\n",
      " [447 'Bengaluru' 'Male' ... 4 1 519360]\n",
      " [501 'Delhi' 'Female' ... 4 1 545501]\n",
      " ...\n",
      " [624 'Bengaluru' 'Male' ... 4 1 259649]\n",
      " [557 'Delhi' 'Male' ... 2 0 538583]\n",
      " [417 'Bengaluru' 'Male' ... 4 0 427703]]\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x=data.iloc[:,0:9].values\n",
    "y=data.iloc[:,-1].values\n",
    "print(x)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2896d-a012-4879-bb38-cbcfad38f7b8",
   "metadata": {},
   "source": [
    "# Apply Label and One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bd00dec-dffb-4d67-a8d6-a94922691e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0 ... 4 1 274150]\n",
      " [1.0 0.0 1 ... 4 1 519360]\n",
      " [0.0 1.0 0 ... 4 1 545501]\n",
      " ...\n",
      " [1.0 0.0 1 ... 4 1 259649]\n",
      " [0.0 1.0 0 ... 2 0 538583]\n",
      " [1.0 0.0 1 ... 4 0 427703]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "x[:,2]=le.fit_transform(x[:,2])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40abf044-54c8-4412-95ba-70a059cd90b8",
   "metadata": {},
   "source": [
    "# Apply One Hot Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8e56a01-8890-47c0-a63d-dec7ba85a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[[0.0 1.0 0.0 ... 4 1 274150]\n",
      " [1.0 0.0 1.0 ... 4 1 519360]\n",
      " [0.0 1.0 0.0 ... 4 1 545501]\n",
      " ...\n",
      " [1.0 0.0 1.0 ... 4 1 259649]\n",
      " [0.0 1.0 0.0 ... 2 0 538583]\n",
      " [1.0 0.0 1.0 ... 4 0 427703]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n",
    "x=np.array(ct.fit_transform(x))\n",
    "le_y = LabelEncoder()\n",
    "y = np.array(le_y.fit_transform(y))\n",
    "print(y)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8f1b7126-1d4b-4f85-937c-5fe43b51ed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 0 0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))\n",
    "print(y_train[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b21e41-411f-4b3c-90d5-e6aa940d4486",
   "metadata": {},
   "source": [
    "# Split data to train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8de093bb-1cdf-4d9f-bf2a-67598e1d21f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5857,)\n",
      "(5857, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "print((y_train).shape)\n",
    "print((x_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f8467-c767-4313-bcb7-33ff0a6308a5",
   "metadata": {},
   "source": [
    "# Feature Scaling of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fe06d41f-6c21-46be-b12f-0400cc113724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b7f8ab-1486-4eed-86eb-235c590753b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Artificial Neural Networks (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe3b05-c5e7-423a-bdb8-89e77b62457c",
   "metadata": {},
   "source": [
    "# Intialaisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ecf48d5-11dc-4a56-9604-f3e0a33c3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Sequential model from Keras\n",
    "# Sequential models are linear stacks of layers where you can add one layer at a time\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51249c4-ac23-49de-89b1-5540d0a32984",
   "metadata": {},
   "source": [
    "# Adding Input Layer and First hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "257fc5a9-6710-4e35-b38e-c0f7c6d9b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a hidden layer to the neural network with 5 neurons and ReLU activation function\n",
    "ann.add(tf.keras.layers.Dense(units=5,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b82722-86f9-4aa2-a258-fe0cb3904a6b",
   "metadata": {},
   "source": [
    "# Adding Second hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95d54d5b-4e57-4b0c-888b-4babc47c102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a hidden layer to the neural network with 5 neurons (units)\n",
    "# and ReLU activation function for introducing non-linearity\n",
    "#Now we will have a input layer 2 hidden, layer 1 hidden layer is created at time of creting input layer\n",
    "ann.add(tf.keras.layers.Dense(units=5,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218ed5a-cd7f-40ab-83d8-e7a3865f7588",
   "metadata": {},
   "source": [
    "# Adding Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e33f737-28fd-4d95-bb22-785cd740d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d71725-64d5-45cb-a30d-ef4997d6f57e",
   "metadata": {},
   "source": [
    "# ANN Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe567b15-d7b7-47d1-99d8-22717868f091",
   "metadata": {},
   "source": [
    "# Compiling ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "23aca6a9-8737-4034-9555-ec349f37c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are diff optimisers in keras which do complex methods to improve performance \n",
    "# 'adam' optimizer: An efficient stochastic gradient descent algorithm that adapts learning rates\n",
    "# 'binary_crossentropy': Loss function ideal for binary classification problems\n",
    "# 'accuracy': Metric to monitor the percentage of correctly classified samples during training\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c3cd2-2c49-4389-ab73-2450d84a680a",
   "metadata": {},
   "source": [
    "# Training on Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b937171d-ecb5-4956-ae53-20ee5a98a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6280 - loss: 0.6811\n",
      "Epoch 2/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.5468\n",
      "Epoch 3/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 0.5088  \n",
      "Epoch 4/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7893 - loss: 0.4862  \n",
      "Epoch 5/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7893 - loss: 0.4711\n",
      "Epoch 6/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7893 - loss: 0.4615\n",
      "Epoch 7/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.4545  \n",
      "Epoch 8/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7890 - loss: 0.4496  \n",
      "Epoch 9/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.4454  \n",
      "Epoch 10/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4422  \n",
      "Epoch 11/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.4390  \n",
      "Epoch 12/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7951 - loss: 0.4362  \n",
      "Epoch 13/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7968 - loss: 0.4337 \n",
      "Epoch 14/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7984 - loss: 0.4318\n",
      "Epoch 15/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7987 - loss: 0.4300\n",
      "Epoch 16/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7994 - loss: 0.4286\n",
      "Epoch 17/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7996 - loss: 0.4280\n",
      "Epoch 18/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4266\n",
      "Epoch 19/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.4255  \n",
      "Epoch 20/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.4249  \n",
      "Epoch 21/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.4243  \n",
      "Epoch 22/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.4233  \n",
      "Epoch 23/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7987 - loss: 0.4221  \n",
      "Epoch 24/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7984 - loss: 0.4209 \n",
      "Epoch 25/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7977 - loss: 0.4199\n",
      "Epoch 26/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 0.4184 \n",
      "Epoch 27/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8028 - loss: 0.4170 \n",
      "Epoch 28/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.4155\n",
      "Epoch 29/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4133  \n",
      "Epoch 30/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8146 - loss: 0.4107 \n",
      "Epoch 31/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.4091\n",
      "Epoch 32/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 0.4073  \n",
      "Epoch 33/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 0.4067  \n",
      "Epoch 34/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 0.4053 \n",
      "Epoch 35/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8194 - loss: 0.4044  \n",
      "Epoch 36/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.4033  \n",
      "Epoch 37/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8216 - loss: 0.4033  \n",
      "Epoch 38/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8209 - loss: 0.4021 \n",
      "Epoch 39/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8204 - loss: 0.4012\n",
      "Epoch 40/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8200 - loss: 0.4005 \n",
      "Epoch 41/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.4000 \n",
      "Epoch 42/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8211 - loss: 0.3989    \n",
      "Epoch 43/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.3988  \n",
      "Epoch 44/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3978    \n",
      "Epoch 45/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.3973  \n",
      "Epoch 46/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.3962  \n",
      "Epoch 47/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8224 - loss: 0.3955  \n",
      "Epoch 48/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8240 - loss: 0.3948  \n",
      "Epoch 49/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8224 - loss: 0.3941   \n",
      "Epoch 50/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8235 - loss: 0.3935\n",
      "Epoch 51/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8245 - loss: 0.3928 \n",
      "Epoch 52/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8265 - loss: 0.3917  \n",
      "Epoch 53/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.3912  \n",
      "Epoch 54/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8277 - loss: 0.3904\n",
      "Epoch 55/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8265 - loss: 0.3898  \n",
      "Epoch 56/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 0.3892  \n",
      "Epoch 57/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8288 - loss: 0.3882  \n",
      "Epoch 58/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.3871  \n",
      "Epoch 59/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.3868  \n",
      "Epoch 60/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.3855  \n",
      "Epoch 61/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.3849\n",
      "Epoch 62/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8328 - loss: 0.3836\n",
      "Epoch 63/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8318 - loss: 0.3825\n",
      "Epoch 64/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.3817  \n",
      "Epoch 65/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 0.3807  \n",
      "Epoch 66/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8346 - loss: 0.3795\n",
      "Epoch 67/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.3800  \n",
      "Epoch 68/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.3783\n",
      "Epoch 69/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 0.3774\n",
      "Epoch 70/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8369 - loss: 0.3770 \n",
      "Epoch 71/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 0.3759 \n",
      "Epoch 72/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.3749 \n",
      "Epoch 73/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3746  \n",
      "Epoch 74/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8398 - loss: 0.3740 \n",
      "Epoch 75/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.3737  \n",
      "Epoch 76/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3725  \n",
      "Epoch 77/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.3726  \n",
      "Epoch 78/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8400 - loss: 0.3720 \n",
      "Epoch 79/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3718 \n",
      "Epoch 80/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.3708  \n",
      "Epoch 81/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.3705 \n",
      "Epoch 82/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8402 - loss: 0.3707  \n",
      "Epoch 83/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.3695\n",
      "Epoch 84/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.3692  \n",
      "Epoch 85/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.3686\n",
      "Epoch 86/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.3700\n",
      "Epoch 87/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.3682\n",
      "Epoch 88/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 0.3677 \n",
      "Epoch 89/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.3672 \n",
      "Epoch 90/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3679 \n",
      "Epoch 91/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8400 - loss: 0.3662 \n",
      "Epoch 92/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3661  \n",
      "Epoch 93/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.3659  \n",
      "Epoch 94/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8428 - loss: 0.3657 \n",
      "Epoch 95/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 0.3649  \n",
      "Epoch 96/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 0.3654\n",
      "Epoch 97/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.3650  \n",
      "Epoch 98/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3648\n",
      "Epoch 99/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.3654 \n",
      "Epoch 100/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8433 - loss: 0.3646  \n",
      "Epoch 101/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.3648  \n",
      "Epoch 102/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8441 - loss: 0.3643 \n",
      "Epoch 103/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3642  \n",
      "Epoch 104/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3638\n",
      "Epoch 105/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.3637\n",
      "Epoch 106/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3633 \n",
      "Epoch 107/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 0.3635  \n",
      "Epoch 108/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3640 \n",
      "Epoch 109/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.3632 \n",
      "Epoch 110/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8417 - loss: 0.3634  \n",
      "Epoch 111/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.3629 \n",
      "Epoch 112/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8445 - loss: 0.3623 \n",
      "Epoch 113/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3634 \n",
      "Epoch 114/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3624 \n",
      "Epoch 115/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 0.3625 \n",
      "Epoch 116/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.3622 \n",
      "Epoch 117/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3618 \n",
      "Epoch 118/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3621  \n",
      "Epoch 119/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8422 - loss: 0.3625  \n",
      "Epoch 120/120\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8428 - loss: 0.3618  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d08ae3a120>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train,epochs=120,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd15aef-43c2-4a03-aef2-af456b44b0e6",
   "metadata": {},
   "source": [
    "# Confusion matrix and Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2bea8bbc-66a6-476c-9394-023329836184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "[[1087   79]\n",
      " [ 170  129]]\n",
      "0.8300341296928327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "y_pred=ann.predict(x_test)\n",
    "y_pred=(y_pred>0.5)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "ac=accuracy_score(y_test,y_pred)\n",
    "print(cm)\n",
    "print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef3be4-5cc1-4af1-960b-ff2a9f359a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
